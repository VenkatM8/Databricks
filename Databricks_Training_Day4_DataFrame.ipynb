{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d89adda8-486c-49ce-8706-3281359c73a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d1dec1-3d91-4d16-85ba-5715a4734dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (\"James\", \"\", \"Smith\", \"36636\", \"M\", 3000),\n",
    "    (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", 4000),\n",
    "    (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 4000),\n",
    "    (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 4000),\n",
    "    (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"zipcode\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data2,schema=columns)\n",
    "display(df)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87545354-1431-4bdc-8cb0-a20d81423a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7c63ae-d0a5-44a1-bd0c-bd906c9b7f7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "\n",
    "# Create RDD\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "# Collect and print\n",
    "rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3aa1dcf-1ecd-46d9-b07a-d391da8d981e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = spark.createDataFrame(data, [\"Language\", \"Salary\"])\n",
    "#dffrd1=rdd.toDFcolumns()\n",
    "    \n",
    "# Show the data\n",
    "#display(df)\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07f901c6-c0e3-40d4-87b5-42b5acc7673f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/FileStore/tables/db_parquet-1.csv\",header=True,inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec7368f7-1755-43a5-b496-2c786831cd5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandasdf=df.toPandas()\n",
    "print(pandasdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2519550-0c6d-4152-9104-cb4c9b2ef7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType, DateType\n",
    " \n",
    "schema = StructType([\n",
    "  StructField(\"PassengerId\", IntegerType(), True),\n",
    "  StructField(\"Survived\", StringType(), True),\n",
    "  StructField(\"Pclass\", IntegerType(), True),\n",
    "  StructField(\"Name\", StringType(), True),\n",
    "  StructField(\"Sex\", StringType(), True),\n",
    "  StructField(\"Age\", FloatType(), True),\n",
    "  StructField(\"SibSp\", IntegerType(), True),\n",
    "  StructField(\"Parch\", IntegerType(), True),\n",
    "  StructField(\"Ticket\", StringType(), True)\n",
    "])  \n",
    " \n",
    "df=spark.read.csv(\"/FileStore/tables/db_parquet-1.csv\",header=True, schema=schema)\n",
    "display(df)\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks_Training_Day4_DataFrame",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
